{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-1jFLWbfesI",
        "outputId": "1defff6f-38c1-48fa-d72e-bca89afee289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# %--------------------------------------------------------------------------\n",
        "# %                                 RADAR B-SCAN\n",
        "# %--------------------------------------------------------------------------\n",
        "# % RESEARCH PROJECT:\n",
        "# % ARTIFICIAL INTELLIGENCE-BASED ALGORITHMS FOR ENHANCED DISCRIMINATION OF \n",
        "# % LANDMINES FROM GPR DATA\n",
        "# %\n",
        "# % UNIVERSIDAD NACIONAL DE COLOMBIA\n",
        "# % TECHNOLOGY INNOVATION INSTITUTE - DIRECTED ENERGY RESEARCH CENTER\n",
        "# %\n",
        "# % RADAR: UWB MIMO-GPR SH-3140 ILMSENS\n",
        "# % This system is composed of four ultra-wideband M-sequence units, labeled \n",
        "# % as T1R2, which are internally synchronized by the CLK unit. Each T1R2 \n",
        "# % unit has one transmitting channel and two receiving channels.\n",
        "# %\n",
        "# % # RADAR HEAD: 4\n",
        "# % # CHANNELS RX PER HEAD: 2\n",
        "# % # CHANNELS TX PER HEAD: 1\n",
        "# % # TOTAL RX: 8\n",
        "# % # TOTAL TX: 4\n",
        "# %--------------------------------------------------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import h5py\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ReadDataRead(rute):\n",
        "  \"\"\"\n",
        "  In this function is extracter data the UWBdata.m the A-scan. return Tensor the (8, frames, 511)\n",
        "  \"\"\"\n",
        "  f = scipy.io.loadmat(rute)\n",
        "  #print(f.keys()) #You look at aditional data on meansures (print title dict)   \n",
        "  frames=f['numFrames'] # in this data Frames\n",
        "  A=f['UWBdata00001'] # in this values the data Frame (It has all A-scan)\n",
        "  B=np.zeros((8,500,511)) # define dimensions of Tensor \n",
        "  B1=A[0][1] # Data the A-scan [max100]\n",
        "  for j in range(8):  # number the head \n",
        "    for k in range(int(frames/100)): # Cycle for extract the 100 data of total the frames\n",
        "      B1=A[k][1]\n",
        "      for i in range(100): \n",
        "        B[j][i+k*100]=[A3[i][j] for A3 in B1] # generate Tensor three dimension where extract data frame per head. \n",
        "       \n",
        "  return B"
      ],
      "metadata": {
        "id": "ELPzSWTwgoE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this function genary in DataFrame in Pandas with rote the measures and other caracteristic than we want graphics. \n",
        "import re\n",
        "def routes(route, objs, confs, days, measures, deeps, poss, metralles=[\"\"]):\n",
        "\n",
        "  \"\"\"\n",
        "   In this function, radargram processing is performed using specific parameters.\n",
        "\n",
        "  Parámetros:\n",
        "      - route (str) The file path of the measurements data. The file path should be provided as a string in the format '/path/to/file'\n",
        "      - objs (list) A list of strings representing the different types of target objects to be processed. The possible values are 'IEDs' or 'Cylinder'.\n",
        "      - confs (list) A list of strings representing the setup configurations for the measurements data. The possible values are 'Monostatic_1'.\n",
        "      - day (list): A list of strings representing the days on which the measurements were taken. The possible values are 'Day_1'  at  ‘Day_3’\n",
        "      - measure (list): A list of integers representing the measurement numbers to be processed. The possible values are 1 at 30.\n",
        "      - deep (list): A list of integers representing the depth of the target object IEDs, for Cylinder is  high antenna. The possible values are 1 for 5cm and 2 for 10cm\n",
        "      - pos (list): A list of integers representing the position of the target object. The possible values are 1 to 4.\n",
        "      - metralle (list): A list of strings representing whether or not the IED has shrapnel. The possible values are 'M' or 'SM'.\n",
        "\n",
        "  Return:\n",
        "\n",
        "      - Dataframe of Pandas with descriptor of the measures. \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize empty lists for file and text\n",
        "  file=[]\n",
        "  text=[]\n",
        "\n",
        "  # Loop through different parameters make patch of UWBdata\n",
        "  for obj in objs:  #by now only IEDs and Cylinder\n",
        "    for conf in confs:\n",
        "      for day in days:\n",
        "        for measure in measures:\n",
        "          measur=int(measure)/100\n",
        "          a=f\"{measur:.2f}\".replace('0.','')\n",
        "          for deep in deeps:\n",
        "            for pos in poss:\n",
        "              for metralle in metralles:\n",
        "                if obj=='IEDs':\n",
        "                  ruta=f'{route}/{obj}/{conf}/{day}/IED_0{a}/IED_0{a}_D{deep}_P{pos}_{metralle}'\n",
        "                elif obj=='Cylinder':\n",
        "                  ruta=f'{route}/{obj}/{conf}/{day}/Cylinder_0{a}/Cylinder_0{a}_TSA800/Cylinder_0{a}_P{pos}_H{deep}_TSA800'\n",
        "\n",
        "                # Read readme.txt file and extract relevant information using regex pattern  \n",
        "                with open(f'{ruta}/readme.txt', 'r') as files:\n",
        "                  readme=(files.read())\n",
        "                  pattern = r'coupler-(.+?)-port'\n",
        "                  wire = re.findall(pattern, readme, flags=re.DOTALL)\n",
        "                  file.append([obj, day, measure, deep, pos, metralle, readme, wire, ruta])\n",
        "\n",
        "  df=pd.DataFrame(columns=['Object','day','measure','deep','position','metralle','readme','wire','route'])\n",
        "  for s in file:\n",
        "    \n",
        "    data = {'Object':s[0],'day':s[1],'measure':s[2],'deep':s[3],'position':s[4],'metralle':s[5],'readme':s[6],'wire':str(s[7]),'route':s[8]}\n",
        "    # Agregar una nueva fila al DataFrame con los valores del diccionario\n",
        "    df = df.append(data, ignore_index=True)\n",
        "    # Update column values in the DataFrame\n",
        "    df.loc[df['deep'] == 1, 'deep'] = \"5 cm\"\n",
        "    df.loc[df['deep'] == 2, 'deep'] = \"10 cm\"\n",
        "    df.loc[df['metralle'] == 'M', 'metralle'] = \"with shrapnel\"\n",
        "    df.loc[df['metralle'] == 'SM', 'metralle'] = \"without shrapnel\"\n",
        "    df.loc[df['Object'] == 'Cylinder', 'metralle'] = \"\"\n",
        "    df = df.drop_duplicates()\n",
        "    df['wire'] = df['wire'].str.strip()\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "yCySimDCgxV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This fuction in  grafica pure/clear raw  using the DataFrame\n",
        "\n",
        "def graphics(df, process=['raw'], save='off', grid='off', lim=[8,1]):\n",
        "\n",
        "  if grid=='on':\n",
        "    plt.style.use('ggplot')\n",
        "  else:\n",
        "    plt.style.use('default')  \n",
        "\n",
        "  \"\"\"\n",
        "  The function \"graphics\" takes a Pandas DataFrame as input, which contains the measurement data of objects.\n",
        "\n",
        "  Parameters:\n",
        "      - process (str): Represents different types of processing data that can be applied to the measurements\n",
        "      - save (str): Represents the method of saving the graphics. It can take three values:\n",
        "      - grid (str): Represents whether the grid should be displayed on the graphics or not\n",
        "      - lim (list): Represents the limits for the y-axis of the graphics.\n",
        "\n",
        "  Return:\n",
        "      Tensor (4,500,511) (array numpy), this data processed \n",
        "  \"\"\"\n",
        "  x=len(df)\n",
        "  vector=np.zeros((x,511,500))\n",
        "\n",
        "  if process[0]=='all':\n",
        "    process=['raw','rm_ant','rm_soil','background']\n",
        "\n",
        "  n=len(process)\n",
        "  for x in range(x):\n",
        "\n",
        "    route= df.iloc[x]['route']\n",
        "\n",
        "    obj = df.iloc[x]['Object']  \n",
        "    day = df.iloc[x]['day']  \n",
        "    measure = df.iloc[x]['measure']  \n",
        "    deep = df.iloc[x]['deep']  \n",
        "    pos = df.iloc[x]['position']  \n",
        "    metralle = df.iloc[x]['metralle']  \n",
        "\n",
        "    if df.iloc[x]['Object']=='IEDs':\n",
        "      title = f'{obj} ({measure})    {day}   deep={deep}    pos={pos}    {metralle}'\n",
        "    if df.iloc[x]['Object']=='Cylinder':\n",
        "      title = f'{obj} ({measure})   {day}    High antenna = {deep}    pos={pos}'\n",
        "\n",
        "    antenna = df.iloc[x]['wire']\n",
        "    pattern = r'cable(.+?)'\n",
        "    antenne = re.findall(pattern, antenna , flags=re.DOTALL)\n",
        "    B = ReadDataRead(f'{route}/UWBdata.mat')\n",
        "    H3_A=B[4];  # H3-RX1\n",
        "\n",
        "\n",
        "    if n>1:\n",
        "      fig, axs = plt.subplots(1, n, figsize=(5*n,5))\n",
        "    else:\n",
        "      fig, axs = plt.subplots() \n",
        "\n",
        "    for i, proces in enumerate(process, start=0):\n",
        "\n",
        "      if proces=='background':\n",
        "\n",
        "        sh = H3_A[0].argmax() #date the Shift.  \n",
        "        st=20\n",
        "        shift =-sh+st\n",
        "\n",
        "        # shift the all matrice\n",
        "\n",
        "        H3_A_sh=np.roll(H3_A,shift)\n",
        "\n",
        "        # filter mean backgrond removal\n",
        "\n",
        "        H3_A_mean = np.mean(H3_A_sh, axis=0)\n",
        "        H3A=(H3_A_sh-H3_A_mean).T\n",
        "        #vector[3]=H3_A_sh\n",
        "        data=H3A\n",
        "        suptitle='Background Removal'\n",
        "              \n",
        "      \n",
        "\n",
        "      elif proces=='rm_ant' or proces=='rm_soil':\n",
        "\n",
        "        if antenne[0]=='1':\n",
        "          rute_ant='/content/drive/Shareddrives/TII UNAL GPR/Data Set Measurements/Dinamic Antenna/Monostatic/dynamic_wire_1'\n",
        "        \n",
        "        elif antenne[0]=='3':\n",
        "          rute_ant='/content/drive/Shareddrives/TII UNAL GPR/Data Set Measurements/Dinamic Antenna/Monostatic/dynamic_wire_3'\n",
        "\n",
        "\n",
        "        ante = ReadDataRead(f'{rute_ant}/UWBdata.mat')\n",
        "\n",
        "        # ant=np.mean(ante[4][0:100], axis=0)\n",
        "        ant = ante[4][0]\n",
        "        sh = ant.argmax() #date the Shift.  \n",
        "        st=20\n",
        "        ant=np.roll(ant, -sh+st)  # position initial and reference\n",
        "\n",
        "        corr_xy = np.correlate(ant, H3_A[1], mode='full') #correlate antenna vs Data Frame\n",
        "        shift = corr_xy.argmax()+1 # calcule data shift\n",
        "\n",
        "        H3_A_sh=np.roll(H3_A,shift)\n",
        "        H3_A_ef=(H3_A_sh-ant)\n",
        "\n",
        "        data=H3_A_ef.T\n",
        "        vec=H3_A_sh[:][:]\n",
        "        vector[x]=vec.T\n",
        "\n",
        "        #vector[1]=data.T\n",
        "        suptitle='Remove effect antenna'\n",
        "\n",
        "\n",
        "      if proces=='rm_soil':\n",
        "\n",
        "        H3_A_ef_max=H3_A_ef[0].argmax()  \n",
        "        H3_A_ef_min=H3_A_ef[0].argmin()\n",
        "        green=np.zeros(511)\n",
        "        delta=2\n",
        "        for n in range(511):\n",
        "          if n>= H3_A_ef_min-2*delta:\n",
        "            if n<= H3_A_ef_max+2*delta:\n",
        "              green[n]=1\n",
        "            else:\n",
        "              green[n]=0\n",
        "          else:\n",
        "            green[n]=0\n",
        "\n",
        "        syn_green=H3_A_ef*green\n",
        "\n",
        "        #rest soil for RadarGrama\n",
        "\n",
        "\n",
        "        H3_A_green=(H3_A_ef-syn_green)\n",
        "\n",
        "        H3_A_green_mean = np.mean(H3_A_green, axis=0)\n",
        "        H3A_green=(H3_A_green-H3_A_green_mean).T\n",
        "\n",
        "        data=H3A_green\n",
        "        #vector[2]=data.T\n",
        "        suptitle='filter soil with Green synthetic function'\n",
        "\n",
        "      if proces=='raw':\n",
        "\n",
        "        sh = H3_A[0].argmax() #date the Shift.  \n",
        "        st=20\n",
        "        shift =-sh+st\n",
        "\n",
        "        # shift the all matrice\n",
        "\n",
        "        H3_A_sh=np.roll(H3_A,shift)\n",
        "\n",
        "        # data=H3_A_sh.T\n",
        "        # vec=H3_A_sh[:][:]\n",
        "        # vector[x]=vec.T\n",
        "        suptitle='raw Data'\n",
        "\n",
        "\n",
        "\n",
        "    # Graphics  \n",
        "      n=len(process)\n",
        "      if n==1:\n",
        "        plt.suptitle(suptitle, fontsize=14, fontweight='bold')\n",
        "        plt.title(suptitle, fontsize=12)\n",
        "        plt.imshow(data, extent=[1, 500, 40, 0], aspect='auto')\n",
        "        plt.ylim(lim[0],lim[1])\n",
        "        plt.xlabel('milimeter')\n",
        "        plt.ylabel('Time [ns]')\n",
        "\n",
        "\n",
        "      else:\n",
        "        #axs[i].set_suptitle(suptitle, fontsize=14, fontweight='bold')\n",
        "        axs[i].set_title(suptitle, fontsize=12)\n",
        "        axs[i].imshow(data, extent=[1, 500, 40, 0], aspect='auto')\n",
        "        axs[i].set_ylim(lim[0],lim[1])\n",
        "        axs[i].set_xlabel('milimeter')\n",
        "        axs[i].set_ylabel('Time [ns]')\n",
        "\n",
        "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
        "    rute_save = f'{route}/{process}.png'\n",
        "    if save=='fig':\n",
        "        # route and name of file at save.\n",
        "      plt.savefig(rute_save)\n",
        "\n",
        "    elif save=='rm':\n",
        "\n",
        "      if os.path.isfile(rute_save):\n",
        "          try:\n",
        "              # Borrar el archivo\n",
        "              os.remove(rute_save )\n",
        "              print(f'file {rute_save} deleted.')\n",
        "          except Exception as e:\n",
        "              print(f'Error deleting file {rute_save}: {e} :(')\n",
        "      else:\n",
        "          print(f'File {rute_save} not is.')\n",
        "\n",
        "    elif save=='data':\n",
        "      arr_2d = vector.reshape(vector.shape[0], -1)\n",
        "      Tensor = pd.DataFrame(arr_2d)\n",
        "      Tensor.to_csv(f'{route}/UWBdata_process.csv', index=False)\n",
        "\n",
        "    elif save=='rm_data':\n",
        "\n",
        "      Tensor_data=f'{route}/UWBdata_process.csv'    \n",
        "      if os.path.isfile(Tensor_data):\n",
        "          try:\n",
        "              # Borrar el archivo\n",
        "              os.remove(Tensor_data )\n",
        "              print(f'file {Tensor_data} deleted.')\n",
        "          except Exception as e:\n",
        "              print(f'Error deleting file {Tensor_data}: {e} :(')\n",
        "      else:\n",
        "          print(f'File {Tensor_data} not is.')      \n",
        " \n",
        "\n",
        "    plt.show()\n",
        "  return vector"
      ],
      "metadata": {
        "id": "tGe3uCvWg3GO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "route ='/content/drive/Shareddrives/TII UNAL GPR/Data Set Measurements' #rute file of the measurements\n",
        "\n",
        "obj=['IEDs']#, 'Cylinder']  # objeto the radargram    'IEDs' or 'Cylinder'\n",
        "conf=['Monostatic_1'] # setup medition \n",
        "day=['Day_1']#, 'Day_2', 'Day_3'] # medition days\n",
        "measure=np.arange(1,31)# number object\n",
        "deep =[1,2]    # Deep the object [1 - 2] 1 for 5cm   and  2 for 10 cm \n",
        "pos = [1,2,3,4]   #Position the [1 at 4]  \n",
        "metralle = ['M','SM'] # this are SM and M   \"with shrapnel\" or \"without shrapnel\".\n",
        "\n",
        "df=routes(route, obj, conf, day, measure, deep, pos, metralle)\n",
        "df\n",
        "Ladmine = graphics(df, process=['raw'], save='off', grid='off', lim=[8,1])"
      ],
      "metadata": {
        "id": "KBZN7ppDhIfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y,z = Ladmine.shape\n",
        "\n",
        "mine=Ladmine[:,19:119,:]\n",
        "mine.shape\n",
        "mine_label=np.ones((x))\n",
        "mine_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZrUNmW7UrOU",
        "outputId": "2e4a3b4d-4312-4544-ffd5-cd3fb7ebe5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(480,)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clutter = graphics(df, process=['raw'], save='off', grid='off', lim=[8,1])"
      ],
      "metadata": {
        "id": "5LGEI7r26rYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y,z = clutter.shape\n",
        "\n",
        "clutter_cy=clutter[:,19:119,:]\n",
        "clutter_cy.shape\n",
        "clutter_label=np.zeros((x))\n",
        "clutter_label.shape\n",
        "\n",
        "# plt.title('hola', fontsize=12)\n",
        "# plt.imshow(clutter_cy[0], extent=[1, 500, 100, 0], aspect='auto')\n",
        "# plt.xlabel('milimeter')\n",
        "# plt.ylabel('Time [ns]')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpHlq7GP7BVm",
        "outputId": "c761b1e1-e9e4-4f0c-a6bf-973226fa194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120,)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "\n",
        "print(mine.shape)\n",
        "print(mine_label.shape)\n",
        "print(clutter_cy.shape)\n",
        "print(clutter_label.shape)\n",
        "\n",
        "datas = np.concatenate((mine, clutter_cy), axis=0)\n",
        "labels = np.concatenate((mine_label, clutter_label), axis=0)\n",
        "\n",
        "print(datas.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "print(labels)\n",
        "## Crear Tensores para importar los datos. \n",
        "\n",
        "with h5py.File('datas.h5', 'w') as f:\n",
        "    f.create_dataset('datas', data=datas)\n",
        "\n",
        "with h5py.File('labels.h5', 'w') as f:\n",
        "    f.create_dataset('labels', data=labels)\n"
      ],
      "metadata": {
        "id": "2fobxdEfVI8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar los datos \n",
        "import h5py\n",
        "\n",
        "with h5py.File('datas.h5', 'r') as f:\n",
        "    data = f['datas'][:]\n",
        "\n",
        "with h5py.File('labels.h5', 'r') as f:\n",
        "    label = f['labels'][:]\n"
      ],
      "metadata": {
        "id": "ap8K2SD6haCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}